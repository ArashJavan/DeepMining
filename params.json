{"name":"Deep Mining","tagline":"Hyperparameter Optimization for Machine Learning Pipelines","body":"## Deep Mining ##\r\n\r\nThis project is hold by [Kalyan Veeramachaneni](http://www.kalyanv.org/) and the [Alfa Group](http://groups.csail.mit.edu/EVO-DesignOpt/groupWebSite/index.php) at CSAIL, MIT.\r\n\r\n### Contributors ###\r\n-----\r\n- [Sebastien Dubois](http://bit.ly/SebastienDubois)\r\n\r\n\r\n\r\n### Overview ###\r\n---------------\r\nThe **Deep Mining** project aims at finding the best hyperparameter set for a Machine Learning pipeline. A pipeline example for the [handwritten digit recognition problem](http://yann.lecun.com/exdb/mnist/) is presented below. Some hyperparameters indeed need to be set carefully, as the degree for the polynomial kernel of the SVM. Choosing the value of such hyperparameters can be a very difficult task and this project's goal is to make it much easier.\r\n\r\n**This software will test iteratively, and smartly, some hyperparameter sets in order to find as quickly as possible the best ones to achieve the best classification accuracy that a pipeline can offer.**\r\n\r\n![Fig2](GCP-HPO/Figures/DeepMining_workflow.png)\r\n\r\n\r\n### Methods ###\r\n---------------\r\nThe folder **GCP-HPO** contains all the code implementing the **Gaussian Copula Process (GCP)** and a **hyperparameter optimization (HPO)** technique based on it. Gaussian Copula Process can be seen as an improved version of the Gaussian Process, that does not assume a Gaussian prior for the marginal distributions but lies on a more complex prior. This new technique is proved to outperform GP-based hyperparameter optimization, which is already far better than the randomized search.\r\n\r\nA paper explaining the GCP approach as well as the hyperparameter process is currently being written and will be linked here as soon as possible. Please consider citing it if you use this work.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}