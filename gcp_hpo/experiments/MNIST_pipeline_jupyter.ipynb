{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running MNIST pipeline entirely online, rather than from csv files like currently done in the experiments folder\n",
    "Steps:\n",
    "    1. Import MNIST data (from Kaggle to be consistent with Sebastien)\n",
    "    2. Blur the training images\n",
    "    3. Reduce image matrices by principal component analysis\n",
    "    4. classify using polynomial SVM\n",
    "\n",
    "Outputs 0.937166667 accuracy on Kaggle test dataset after training on entire train dataset\n",
    "\"\"\"\n",
    "    \n",
    "# from gcp_hpo.smart_search import SmartSearch\n",
    "# from ..smart_search import SmartSearch # Alec edit\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make iPython notebook take up whole screen\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# Print more items in numpy arrays\n",
    "np.set_printoptions(edgeitems=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cv2 implementation allows us to do the Gaussian blur, but only for odd values of the kernel size,\n",
    "# so not incorporating for now\n",
    "# from cv2 import GaussianBlur\n",
    "\n",
    "# def gaussian_blur(img):\n",
    "#     return GaussianBlur(img,(5,5),sigmaX=4)\n",
    "\n",
    "# print gaussian_blur(X_train[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "blur_ksize = 1 # Fixed at this value\n",
    "blur_sigma = 4\n",
    "pca_dim = 60\n",
    "degree_poly = 3\n",
    "gamma = 10**(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    data = np.loadtxt('/Users/aandersonlaptop/Desktop/MNIST_train.csv',skiprows=1,delimiter=',')\n",
    "    train_x = data[:40000,1:]\n",
    "    train_y = data[:40000,0]\n",
    "    # print 'train Y',train_y\n",
    "    # print 'train X',train_x\n",
    "    test_x = data[40000:,1:]\n",
    "    test_y = data[40000:,0]\n",
    "    \n",
    "    # print 'test X',test_x\n",
    "    return train_x,train_y,test_x,test_y\n",
    "    \n",
    "    \n",
    "X_train,y_train,X_test,y_test = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 784)\n"
     ]
    }
   ],
   "source": [
    "def gaussian_blur(X,stddev):\n",
    "    # This fixes a kernel size, can incorporate changing kernel sizes later using scipy generic_filter or opencv\n",
    "    return gaussian_filter(X,sigma=stddev,order=0)\n",
    "\n",
    "blurred_X_train = gaussian_blur(X_train,stddev=blur_sigma)\n",
    "print blurred_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_pca(X,num_components,fit,fitted_model=None):\n",
    "    if fit:\n",
    "        pca = PCA(n_components = num_components)\n",
    "        pca = pca.fit(X)\n",
    "        return pca,pca.transform(X)\n",
    "    else:\n",
    "        return fitted_model.transform(X)\n",
    "    \n",
    "pca_model,pca_X_train = do_pca(blurred_X_train,num_components=pca_dim,fit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_sample(X,y,num_samples):\n",
    "    idx = np.random.randint(X.shape[0],size=num_samples)\n",
    "    return X[idx],y[idx]\n",
    "\n",
    "X_sample,y_sample = random_sample(pca_X_train,y_train,15000)\n",
    "print 'shape',X_sample.shape\n",
    "print 'shape',y_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def do_svm(X,y,degree,gamma_coeff):\n",
    "#     clf = SVC(kernel='poly',degree=degree,gamma=gamma_coeff)\n",
    "#     clf.fit(X,y)\n",
    "#     print 'accuracy on training set',clf.score(X,y)\n",
    "#     return clf\n",
    "\n",
    "# # model = do_svm(pca_X_train,y_train,degree=degree_poly,gamma_coeff=gamma) # Whole training set\n",
    "# model = do_svm(pca_X_train,y_train,degree=degree_poly,gamma_coeff=gamma)\n",
    "# model = do_svm(X_train[:5000,:],y_train[:5000],degree=degree_poly,gamma_coeff=gamma)\n",
    "# model = do_svm(X_sample,y_sample,degree=degree_poly,gamma_coeff=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set 0.979425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest(X,y,num_estimators):\n",
    "    clf = RandomForestClassifier(n_estimators=num_estimators)\n",
    "    clf.fit(X,y)\n",
    "    print 'accuracy on training set',clf.score(X,y)\n",
    "    return clf\n",
    "\n",
    "model = random_forest(pca_X_train,y_train,num_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ############################# Test model ############################\n",
    "# def import_test_data():\n",
    "#     # Import MNIST data\n",
    "#     data = np.loadtxt('/Users/aandersonlaptop/Desktop/MNIST_test.csv',skiprows=1,delimiter=',') # way slower than pandas\n",
    "#     new_x = data[:,1:]\n",
    "#     new_y = data[:,0]\n",
    "#     print 'Y',new_y\n",
    "#     print 'X',new_x\n",
    "#     return new_x,new_y\n",
    "\n",
    "# X_test,y_test = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1695\n"
     ]
    }
   ],
   "source": [
    "### Test model ###\n",
    "\n",
    "blurred_X_test = gaussian_blur(X_test,stddev=blur_sigma)\n",
    "pca_X_test = do_pca(blurred_X_test,num_components=pca_dim,fit=False,fitted_model=pca_model)\n",
    "print model.score(pca_X_test,y_test)\n",
    "# print model.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
